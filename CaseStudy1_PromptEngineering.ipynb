{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1: Prompt Engineering – Customer Support Chatbot\n",
    "\n",
    "## Problem Statement\n",
    "The goal of this case study is to design effective prompts for a Large Language Model (LLM) to answer customer FAQs.\n",
    "We will experiment with three prompt styles: Zero-shot, Few-shot, and Role-based prompting.\n",
    "\n",
    "**Dataset:** A CSV file containing FAQs with columns: `question`, `answer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load FAQ dataset\n",
    "faq_path = 'faq_dataset.csv'  # Ensure the dataset is in the same directory as this notebook\n",
    "faq_df = pd.read_csv(faq_path)\n",
    "faq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Zero-shot Prompting\n",
    "Ask the model directly without providing any examples.\n",
    "\n",
    "### Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "query = \"How can I track my order?\"\n",
    "\n",
    "response_zero = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "print(response_zero.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Few-shot Prompting\n",
    "Provide 2–3 Q&A examples before asking the real query.\n",
    "\n",
    "### Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your return policy?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"You can return items within 30 days of purchase.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you ship internationally?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Yes, we ship worldwide with standard shipping rates.\"}\n",
    "]\n",
    "\n",
    "query = \"How can I track my order?\"\n",
    "messages = examples + [{\"role\": \"user\", \"content\": query}]\n",
    "\n",
    "response_few = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=messages\n",
    ")\n",
    "print(response_few.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Role-based Prompting\n",
    "Define a system role to guide the model.\n",
    "\n",
    "### Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I track my order?\"\n",
    "\n",
    "response_role = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful customer support agent. Always answer clearly and politely.\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "print(response_role.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Results\n",
    "We will store all responses in a comparison table for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Prompt Style': ['Zero-shot', 'Few-shot', 'Role-based'],\n",
    "    'Response': [\n",
    "        response_zero.choices[0].message['content'],\n",
    "        response_few.choices[0].message['content'],\n",
    "        response_role.choices[0].message['content']\n",
    "    ]\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- Which prompt style worked best?\n",
    "- Did the few-shot examples improve accuracy?\n",
    "- Did role-based instructions make responses clearer or more professional?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}